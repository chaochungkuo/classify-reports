{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Feature Selection\"\n",
    "author:\n",
    "  Chao-Chung Kuo\n",
    "date: today\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 3\n",
    "    toc-expand: 3\n",
    "    toc-location: left\n",
    "    html-math-method: katex\n",
    "    code-fold: true\n",
    "    code-tools: true\n",
    "    embed-resources: true\n",
    "    page-layout: full\n",
    "    html-table-processing: none\n",
    "    other-links:\n",
    "      - text: Main Report\n",
    "        href: index.html\n",
    "execute:\n",
    "    echo: true\n",
    "    warning: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Feature Selection\n",
    "\n",
    "## Overview\n",
    "This notebook selects the most informative features for the classification task, using only the training data to avoid data leakage. The number of features and the selection method are defined in `config.toml`.\n",
    "\n",
    "**Key steps:**\n",
    "- Load processed data from preprocessing\n",
    "- Fit feature selection on training data only\n",
    "- Apply selected features to both train and test sets\n",
    "- Visualize feature importances and selection results\n",
    "- Save reduced datasets and selection info for modeling\n",
    "\n",
    "**Why feature selection?**\n",
    "- Reduces overfitting\n",
    "- Improves model interpretability\n",
    "- Speeds up training and inference\n",
    "- Can improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import toml\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load config\n",
    "config = toml.load('../config.toml')\n",
    "fs_config = config['feature_selection']\n",
    "n_features = fs_config.get('n_features', 50)\n",
    "method = fs_config.get('method', 'model_importance')\n",
    "scoring = fs_config.get('scoring', 'f_classif')\n",
    "\n",
    "print(f\"Feature selection method: {method}\")\n",
    "print(f\"Number of features to select: {n_features}\")\n",
    "print(f\"Scoring/model: {scoring}\")\n",
    "\n",
    "# Apply visualization settings from config\n",
    "if 'visualization' in config:\n",
    "    if 'dpi' in config['visualization']:\n",
    "        plt.rcParams['figure.dpi'] = config['visualization']['dpi']\n",
    "    if 'figure_size' in config['visualization']:\n",
    "        plt.rcParams['figure.figsize'] = config['visualization']['figure_size']\n",
    "    if 'color_palette' in config['visualization']:\n",
    "        sns.set_palette(config['visualization']['color_palette'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data from previous step\n",
    "data_dir = Path('../data/processed')\n",
    "with open(data_dir / '03_processed_data.pkl', 'rb') as f:\n",
    "    processed_data = pickle.load(f)\n",
    "\n",
    "X_train = pd.DataFrame(processed_data['X_train'], columns=processed_data['feature_cols'])\n",
    "X_test = pd.DataFrame(processed_data['X_test'], columns=processed_data['feature_cols'])\n",
    "y_train = processed_data['y_train']\n",
    "y_test = processed_data['y_test']\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Feature Selection Strategy\n",
    "\n",
    "We will fit the feature selection method **only on the training data** to avoid data leakage. The selected features will then be used to filter both the training and test sets.\n",
    "\n",
    "**Supported methods:**\n",
    "- `select_k_best`: Univariate feature selection (requires `scoring`)\n",
    "    - `f_classif`: ANOVA F-value\n",
    "    - `mutual_info`: Mutual information\n",
    "- `model_importance`: Model-based (e.g., Random Forest)\n",
    "- `variance`: Variance threshold (not supervised)\n",
    "- `rfe`, `lasso`, etc. (future extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = fs_config.get('method', 'select_k_best')\n",
    "scoring = fs_config.get('scoring', 'f_classif')\n",
    "n_features = fs_config.get('n_features', 100)\n",
    "\n",
    "if method == 'select_k_best':\n",
    "    if scoring == 'f_classif':\n",
    "        selector = SelectKBest(score_func=f_classif, k=n_features)\n",
    "    elif scoring == 'mutual_info':\n",
    "        selector = SelectKBest(score_func=mutual_info_classif, k=n_features)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown scoring function for select_k_best: {scoring}\")\n",
    "    selector.fit(X_train, y_train)\n",
    "    scores = selector.scores_\n",
    "    feature_scores = pd.Series(scores, index=X_train.columns)\n",
    "    selected_mask = selector.get_support()\n",
    "    selected_features = X_train.columns[selected_mask]\n",
    "    importance_type = scoring\n",
    "elif method == 'model_importance':\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    importances = rf.feature_importances_\n",
    "    feature_scores = pd.Series(importances, index=X_train.columns)\n",
    "    selected_features = feature_scores.sort_values(ascending=False).head(n_features).index\n",
    "    selected_mask = X_train.columns.isin(selected_features)\n",
    "    importance_type = \"Random Forest Importance\"\n",
    "elif method == 'variance':\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "    selector = VarianceThreshold()\n",
    "    selector.fit(X_train)\n",
    "    variances = selector.variances_\n",
    "    feature_scores = pd.Series(variances, index=X_train.columns)\n",
    "    selected_features = feature_scores.sort_values(ascending=False).head(n_features).index\n",
    "    selected_mask = X_train.columns.isin(selected_features)\n",
    "    importance_type = \"Variance\"\n",
    "else:\n",
    "    raise ValueError(f\"Unknown feature selection method: {method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importances\n",
    "plt.figure()\n",
    "top_n = min(30, len(selected_features))\n",
    "feature_scores[selected_features].sort_values(ascending=False)[:top_n].plot(kind='bar')\n",
    "plt.title(f\"Top {top_n} Selected Features by {importance_type}\")\n",
    "plt.ylabel(importance_type)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize before/after feature count\n",
    "before = X_train.shape[1]\n",
    "after = len(selected_features)\n",
    "\n",
    "plt.figure()\n",
    "bars = plt.bar(['Before', 'After'], [before, after], color=['gray', 'green'])\n",
    "plt.title(\"Number of Features Before and After Selection\")\n",
    "plt.ylabel(\"Feature Count\")\n",
    "\n",
    "# Add number labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height + 1,  # +1 = offset\n",
    "             str(int(height)), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "data = X_train[selected_features]\n",
    "data.index = processed_data[\"train_indices\"]\n",
    "labels = y_train.loc[data.index]\n",
    "\n",
    "# Map class labels to colors\n",
    "palette = sns.color_palette(\"Set2\", n_colors=labels.nunique())\n",
    "label_to_color = dict(zip(labels.unique(), palette))\n",
    "col_colors = labels.map(label_to_color)\n",
    "\n",
    "# Plot clustered heatmap\n",
    "g = sns.clustermap(data.T,\n",
    "                   cmap='viridis',\n",
    "                   figsize=(10, 5),\n",
    "                   standard_scale=1,\n",
    "                   row_cluster=True,\n",
    "                   col_cluster=True,\n",
    "                   col_colors=col_colors,              # ← annotate columns by y_train\n",
    "                   dendrogram_ratio=(0.1, 0.1),       # ← shrink top dendrogram\n",
    "                   cbar_pos=(0.03, 0.9, 0.015, 0.1))    # ← top-left, narrow & separated\n",
    "# Hide x-axis ticks and labels\n",
    "g.ax_heatmap.set_xticks([])\n",
    "g.ax_heatmap.set_xticklabels([])\n",
    "# Fix title and layout\n",
    "g.fig.suptitle(\"Clustered Heatmap of Selected Features\", y=1.03)\n",
    "\n",
    "# Optional: Add legend for labels\n",
    "for label, color in label_to_color.items():\n",
    "    g.ax_col_dendrogram.bar(0, 0, color=color, label=label, linewidth=0)\n",
    "g.ax_col_dendrogram.legend(loc=\"right\", ncol=1, bbox_to_anchor=(1.2, 1.2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset both train and test sets to selected features\n",
    "X_train_selected = X_train[selected_features].copy()\n",
    "X_test_selected = X_test[selected_features].copy()\n",
    "\n",
    "print(f\"Reduced training set shape: {X_train_selected.shape}\")\n",
    "print(f\"Reduced test set shape: {X_test_selected.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reduced datasets and feature selection info\n",
    "output = {\n",
    "    'X_train_selected': X_train_selected,\n",
    "    'X_test_selected': X_test_selected,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    'selected_features': list(selected_features),\n",
    "    'feature_scores': feature_scores.to_dict(),\n",
    "    'method': method,\n",
    "    'importance_type': importance_type\n",
    "}\n",
    "\n",
    "with open(data_dir / '04_feature_selection.pkl', 'wb') as f:\n",
    "    pickle.dump(output, f)\n",
    "\n",
    "print(\"Feature selection results saved to 04_feature_selection.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Selected the top features using **only the training data** and the method specified in `config.toml`\n",
    "- Visualized feature importances and the effect of selection\n",
    "- Saved the reduced datasets and selection info for modeling\n",
    "\n",
    "**Next:**  \n",
    "Proceed to model training using only the selected features for both training and test sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
