{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Data Preprocessing and Feature Engineering\"\n",
    "author:\n",
    "  Chao-Chung Kuo\n",
    "date: today\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 3\n",
    "    toc-expand: 3\n",
    "    toc-location: left\n",
    "    html-math-method: katex\n",
    "    code-fold: true\n",
    "    code-tools: true\n",
    "    embed-resources: true\n",
    "    page-layout: full\n",
    "    html-table-processing: none\n",
    "    other-links:\n",
    "      - text: Main Report\n",
    "        href: index.html\n",
    "execute:\n",
    "    echo: true\n",
    "    warning: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Data Preprocessing and Feature Engineering\n",
    "\n",
    "## Overview\n",
    "This notebook performs comprehensive data preprocessing and feature engineering following machine learning best practices. The key principle is to prevent data leakage by splitting the data early and using only training data to fit any transformers.\n",
    "\n",
    "## Critical Workflow Order\n",
    "1. **Data Cleaning** (Before Split) - Handle missing values, outliers, duplicates\n",
    "2. **Train-Test Split** (Early) - Split data to prevent leakage\n",
    "3. **Feature Engineering** (After Split) - Use only training data to fit transformers\n",
    "4. **Apply Transformers** - Use fitted transformers on both training and test data\n",
    "5. **Validation** - Ensure quality and no data leakage\n",
    "6. **Save Results** - Store processed data for modeling\n",
    "\n",
    "## Why This Order Matters\n",
    "- **Data Leakage Prevention**: Test set remains completely unseen during feature engineering\n",
    "- **Realistic Evaluation**: Model performance reflects real-world scenarios\n",
    "- **Reproducibility**: All transformations are documented and saved\n",
    "- **Best Practices**: Follows standard machine learning workflow\n",
    "\n",
    "## What We'll Accomplish\n",
    "✅ Clean data of missing values, outliers, and duplicates\n",
    "✅ Split data into training and test sets\n",
    "✅ Engineer features using only training data\n",
    "✅ Apply consistent transformations to both datasets\n",
    "✅ Validate preprocessing quality\n",
    "✅ Save everything for the modeling phase\n",
    "\n",
    "All preprocessing steps are configurable through `config.toml` for reproducibility and consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "==================================================\n",
      "Preprocessing Configuration:\n",
      "Imputation strategy: mean\n",
      "Outlier method: iqr\n",
      "Normalization method: zscore\n",
      "Test size: 0.2\n",
      "Random state: 42\n",
      "Stratify split: True\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy import stats\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configuration\n",
    "import toml\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load configuration\n",
    "config = toml.load('../config.toml')\n",
    "\n",
    "# Display preprocessing configuration\n",
    "print(\"Preprocessing Configuration:\")\n",
    "print(f\"Imputation strategy: {config['preprocessing']['imputation_strategy']}\")\n",
    "print(f\"Outlier method: {config['preprocessing']['outlier_method']}\")\n",
    "print(f\"Normalization method: {config['preprocessing']['normalization_method']}\")\n",
    "print(f\"Test size: {config['split']['test_size']}\")\n",
    "print(f\"Random state: {config['split']['random_state']}\")\n",
    "print(f\"Stratify split: {config['split']['stratify']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Loading Data and Previous Analysis Results\n",
    "\n",
    "Before we begin preprocessing, we need to load:\n",
    "1. **Original Data**: The raw dataset from the first notebook\n",
    "2. **EDA Results**: Quality assessment and findings from the second notebook\n",
    "3. **Metadata**: Information about columns and data structure\n",
    "\n",
    "This ensures our preprocessing decisions are informed by the comprehensive analysis we performed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from previous notebooks...\n",
      "==================================================\n",
      "Data loaded successfully!\n",
      "Original dataset shape: (30, 32)\n",
      "Number of features: 30\n",
      "Number of samples: 30\n",
      "Target variable: label\n",
      "Label distribution: {'A': 10, 'B': 10, 'C': 10}\n",
      "\n",
      "EDA Quality Score: 100/100\n",
      "Missing values: 0.00%\n",
      "Outliers: 1.22%\n",
      "Class balance ratio: 1.000\n",
      "\n",
      "EDA Recommendations (0):\n",
      "\n",
      "Analysis performed at: 2025-07-03T11:30:31.114552\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Loading data from previous notebooks...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define data directory\n",
    "data_dir = Path('../data/processed')\n",
    "\n",
    "# Load data objects from data ingestion\n",
    "with open(data_dir / '01_data_ingestion.pkl', 'rb') as f:\n",
    "    ingestion_data = pickle.load(f)\n",
    "\n",
    "# Load EDA results\n",
    "with open(data_dir / '02_eda_results.pkl', 'rb') as f:\n",
    "    eda_results = pickle.load(f)\n",
    "\n",
    "# Extract data components\n",
    "df = ingestion_data['data']['df'].copy()  # Make a copy to avoid modifying original\n",
    "feature_cols = ingestion_data['data']['feature_cols']\n",
    "sample_id_col = ingestion_data['metadata']['sample_id_col']\n",
    "label_col = ingestion_data['metadata']['label_col']\n",
    "\n",
    "# Extract metadata\n",
    "n_features = ingestion_data['metadata']['n_features']\n",
    "n_samples = ingestion_data['metadata']['n_samples']\n",
    "label_distribution = ingestion_data['metadata']['label_distribution']\n",
    "\n",
    "# Extract EDA results\n",
    "quality_metrics = eda_results['quality_metrics']\n",
    "recommendations = eda_results['recommendations']\n",
    "quality_score = eda_results['quality_score']\n",
    "correlation_matrix = eda_results['correlation_matrix']\n",
    "high_corr_pairs = eda_results['high_corr_pairs']\n",
    "outliers_by_feature = eda_results['outliers_by_feature']\n",
    "class_distribution = eda_results['class_distribution']\n",
    "feature_variances = eda_results['feature_variances']\n",
    "analysis_timestamp = eda_results['analysis_timestamp']\n",
    "\n",
    "# Summary printout\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Number of features: {n_features}\")\n",
    "print(f\"Number of samples: {n_samples}\")\n",
    "print(f\"Target variable: {label_col}\")\n",
    "print(f\"Label distribution: {label_distribution}\")\n",
    "\n",
    "# EDA Summary\n",
    "print(f\"\\nEDA Quality Score: {quality_score}/100\")\n",
    "print(f\"Missing values: {quality_metrics['missing_values_percent']:.2f}%\")\n",
    "print(f\"Outliers: {quality_metrics['outlier_percent']:.2f}%\")\n",
    "print(f\"Class balance ratio: {quality_metrics['class_balance_ratio']:.3f}\")\n",
    "\n",
    "# Show EDA recommendations\n",
    "print(f\"\\nEDA Recommendations ({len(recommendations)}):\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"  {i}. {rec}\")\n",
    "\n",
    "# Timestamp info\n",
    "print(f\"\\nAnalysis performed at: {analysis_timestamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Preprocessing Plan\n",
    "\n",
    "Based on our EDA findings and best practices, we'll implement the following preprocessing steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Data Cleaning\n",
    "\n",
    "### Step 1: Missing Value Treatment\n",
    "\n",
    "**Why handle missing values before splitting?**\n",
    "- Missing values can affect the split process\n",
    "- Basic cleaning should be done on the entire dataset\n",
    "- No risk of data leakage for simple imputation\n",
    "\n",
    "**Imputation Strategies:**\n",
    "- **Mean**: Replace with feature mean (good for normally distributed data)\n",
    "- **Median**: Replace with feature median (robust to outliers)\n",
    "- **Most Frequent**: Replace with most common value (good for categorical data)\n",
    "- **KNN**: Use k-nearest neighbors to estimate missing values\n",
    "- **None**: Remove rows with missing values (if missing data is minimal)\n",
    "\n",
    "**Our Approach:**\n",
    "1. Analyze missing value patterns\n",
    "2. Choose appropriate imputation strategy from config\n",
    "3. Apply imputation to features and handle target separately\n",
    "4. Validate imputation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: Data Cleaning\n",
      "==================================================\n",
      "Step 1: Missing Value Treatment\n",
      "------------------------------\n",
      "Missing Value Analysis:\n",
      "Total missing values: 0\n",
      "Overall missing percentage: 0.00%\n",
      "\n",
      "✓ No missing values found in features.\n",
      "\n",
      "✓ No missing values in target variable\n",
      "\n",
      "Applying imputation strategy: mean\n",
      "✓ No imputation needed (no missing values or strategy is 'none')\n",
      "\n",
      "Validation:\n",
      "Missing values after imputation: 0\n",
      "✓ All missing values have been successfully handled\n",
      "Dataset shape after missing value treatment: (30, 32)\n"
     ]
    }
   ],
   "source": [
    "# Phase 1: Data Cleaning\n",
    "print(\"Phase 1: Data Cleaning\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Step 1: Missing Value Treatment\n",
    "print(\"Step 1: Missing Value Treatment\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Analyze missing values\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "print(\"Missing Value Analysis:\")\n",
    "print(f\"Total missing values: {missing_data.sum()}\")\n",
    "print(f\"Overall missing percentage: {missing_data.sum() / (len(df) * len(df.columns)) * 100:.2f}%\")\n",
    "\n",
    "# Show features with missing values\n",
    "features_with_missing = missing_data[missing_data > 0]\n",
    "if len(features_with_missing) > 0:\n",
    "    print(f\"\\nFeatures with missing values ({len(features_with_missing)}):\")\n",
    "    for feature, count in features_with_missing.items():\n",
    "        print(f\"  {feature}: {count} ({missing_percent[feature]:.2f}%)\")\n",
    "else:\n",
    "    print(\"\\n✓ No missing values found in features.\")\n",
    "\n",
    "# Check target variable for missing values\n",
    "if df[label_col].isnull().sum() > 0:\n",
    "    print(f\"\\n⚠️  Missing values in target variable: {df[label_col].isnull().sum()}\")\n",
    "    # Remove rows with missing target (we can't impute the target)\n",
    "    df = df.dropna(subset=[label_col])\n",
    "    print(f\"Removed {len(df)} rows with missing target values\")\n",
    "else:\n",
    "    print(f\"\\n✓ No missing values in target variable\")\n",
    "\n",
    "# Apply imputation strategy\n",
    "imputation_strategy = config['preprocessing']['imputation_strategy']\n",
    "print(f\"\\nApplying imputation strategy: {imputation_strategy}\")\n",
    "\n",
    "if imputation_strategy != \"none\" and len(features_with_missing) > 0:\n",
    "    # Prepare feature data for imputation\n",
    "    X_features = df[feature_cols].copy()\n",
    "    \n",
    "    if imputation_strategy == \"mean\":\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        print(\"Using mean imputation (average value for each feature)\")\n",
    "        \n",
    "    elif imputation_strategy == \"median\":\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        print(\"Using median imputation (middle value for each feature)\")\n",
    "        \n",
    "    elif imputation_strategy == \"most_frequent\":\n",
    "        imputer = SimpleImputer(strategy='most_frequent')\n",
    "        print(\"Using most frequent imputation (most common value for each feature)\")\n",
    "        \n",
    "    elif imputation_strategy == \"knn\":\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        print(\"Using KNN imputation (k=5 nearest neighbors)\")\n",
    "    \n",
    "    # Fit and transform\n",
    "    X_imputed = imputer.fit_transform(X_features)\n",
    "    df[feature_cols] = X_imputed\n",
    "    \n",
    "    print(\"✓ Imputation completed successfully\")\n",
    "    \n",
    "    # Save imputer for later use\n",
    "    imputer_info = {\n",
    "        'imputer': imputer,\n",
    "        'strategy': imputation_strategy,\n",
    "        'features_imputed': list(features_with_missing.index)\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    print(\"✓ No imputation needed (no missing values or strategy is 'none')\")\n",
    "    imputer_info = None\n",
    "\n",
    "# Validate imputation\n",
    "missing_after = df.isnull().sum().sum()\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"Missing values after imputation: {missing_after}\")\n",
    "if missing_after == 0:\n",
    "    print(\"✓ All missing values have been successfully handled\")\n",
    "else:\n",
    "    print(f\"⚠️  {missing_after} missing values remain\")\n",
    "\n",
    "print(f\"Dataset shape after missing value treatment: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Outlier Detection and Treatment\n",
    "\n",
    "**Why handle outliers before splitting?**\n",
    "- Outliers can affect the split process and class distribution\n",
    "- Basic outlier treatment doesn't involve complex statistics\n",
    "- No risk of data leakage for simple outlier methods\n",
    "\n",
    "**Outlier Detection Methods:**\n",
    "- **IQR Method**: Uses interquartile range (Q3 - Q1) to identify outliers\n",
    "- **Z-Score Method**: Uses standard deviations from the mean\n",
    "- **Isolation Forest**: Machine learning approach to detect outliers\n",
    "- **None**: Skip outlier detection\n",
    "\n",
    "**Treatment Strategies:**\n",
    "- **Remove**: Delete outlier samples (if percentage is low)\n",
    "- **Cap**: Limit outliers to reasonable bounds\n",
    "- **Investigate**: Flag for manual review (if percentage is high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Outlier Detection and Treatment\n",
      "----------------------------------------\n",
      "Using outlier detection method: iqr\n",
      "Using IQR method for outlier detection\n",
      "Outliers: values < Q1 - 1.5*IQR or > Q3 + 1.5*IQR\n",
      "  feature_1: 1 outliers (3.3%)\n",
      "  feature_5: 1 outliers (3.3%)\n",
      "  feature_9: 1 outliers (3.3%)\n",
      "  feature_11: 2 outliers (6.7%)\n",
      "  feature_13: 1 outliers (3.3%)\n",
      "  feature_19: 2 outliers (6.7%)\n",
      "  feature_29: 1 outliers (3.3%)\n",
      "  feature_30: 2 outliers (6.7%)\n",
      "\n",
      "Outlier Analysis:\n",
      "Total unique samples with outliers: 11\n",
      "Percentage of samples with outliers: 36.7%\n",
      "⚠️  High outlier percentage - will cap outliers\n",
      "\n",
      "Capping outliers to 95th and 5th percentiles...\n",
      "✓ Outliers capped successfully\n",
      "Dataset shape after outlier treatment: (30, 32)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Outlier Detection and Treatment\n",
    "print(\"\\nStep 2: Outlier Detection and Treatment\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "outlier_method = config['preprocessing']['outlier_method']\n",
    "print(f\"Using outlier detection method: {outlier_method}\")\n",
    "\n",
    "# Prepare data for outlier detection\n",
    "X_features = df[feature_cols].copy()\n",
    "\n",
    "outlier_info = {\n",
    "    'method': outlier_method,\n",
    "    'outliers_by_feature': {},\n",
    "    'total_outliers': 0,\n",
    "    'outlier_indices': set()\n",
    "}\n",
    "\n",
    "if outlier_method == \"iqr\":\n",
    "    print(\"Using IQR method for outlier detection\")\n",
    "    print(\"Outliers: values < Q1 - 1.5*IQR or > Q3 + 1.5*IQR\")\n",
    "    \n",
    "    for col in feature_cols:\n",
    "        Q1 = X_features[col].quantile(0.25)\n",
    "        Q3 = X_features[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = ((X_features[col] < lower_bound) | (X_features[col] > upper_bound))\n",
    "        outlier_count = outliers.sum()\n",
    "        outlier_info['outliers_by_feature'][col] = outlier_count\n",
    "        outlier_info['total_outliers'] += outlier_count\n",
    "        \n",
    "        if outlier_count > 0:\n",
    "            outlier_indices = outliers[outliers].index\n",
    "            outlier_info['outlier_indices'].update(outlier_indices)\n",
    "            \n",
    "            print(f\"  {col}: {outlier_count} outliers ({outlier_count/len(df)*100:.1f}%)\")\n",
    "\n",
    "elif outlier_method == \"zscore\":\n",
    "    print(\"Using Z-score method for outlier detection\")\n",
    "    print(\"Outliers: values with |z-score| > 3\")\n",
    "    \n",
    "    z_scores = np.abs(stats.zscore(X_features))\n",
    "    threshold = 3.0\n",
    "    \n",
    "    for i, col in enumerate(feature_cols):\n",
    "        outliers = z_scores[:, i] > threshold\n",
    "        outlier_count = outliers.sum()\n",
    "        outlier_info['outliers_by_feature'][col] = outlier_count\n",
    "        outlier_info['total_outliers'] += outlier_count\n",
    "        \n",
    "        if outlier_count > 0:\n",
    "            outlier_indices = np.where(outliers)[0]\n",
    "            outlier_info['outlier_indices'].update(outlier_indices)\n",
    "            \n",
    "            print(f\"  {col}: {outlier_count} outliers ({outlier_count/len(df)*100:.1f}%)\")\n",
    "\n",
    "elif outlier_method == \"isolation_forest\":\n",
    "    print(\"Using Isolation Forest for outlier detection\")\n",
    "    \n",
    "    iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "    outlier_labels = iso_forest.fit_predict(X_features)\n",
    "    outliers = outlier_labels == -1\n",
    "    outlier_count = outliers.sum()\n",
    "    \n",
    "    outlier_info['total_outliers'] = outlier_count\n",
    "    outlier_info['outlier_indices'] = set(np.where(outliers)[0])\n",
    "    \n",
    "    print(f\"  Total outliers detected: {outlier_count} ({outlier_count/len(df)*100:.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping outlier detection (method: none)\")\n",
    "\n",
    "# Analyze outlier impact and decide treatment\n",
    "if outlier_info['total_outliers'] > 0:\n",
    "    outlier_percentage = len(outlier_info['outlier_indices']) / len(df) * 100\n",
    "    print(f\"\\nOutlier Analysis:\")\n",
    "    print(f\"Total unique samples with outliers: {len(outlier_info['outlier_indices'])}\")\n",
    "    print(f\"Percentage of samples with outliers: {outlier_percentage:.1f}%\")\n",
    "    \n",
    "    # Decide on treatment strategy\n",
    "    if outlier_percentage > 20:\n",
    "        print(\"⚠️  High outlier percentage - will cap outliers\")\n",
    "        treatment_strategy = \"cap\"\n",
    "    elif outlier_percentage > 5:\n",
    "        print(\"Moderate outlier percentage - will cap outliers\")\n",
    "        treatment_strategy = \"cap\"\n",
    "    else:\n",
    "        print(\"Low outlier percentage - will remove outliers\")\n",
    "        treatment_strategy = \"remove\"\n",
    "    \n",
    "    # Apply treatment\n",
    "    if treatment_strategy == \"remove\":\n",
    "        print(\"\\nRemoving outlier samples...\")\n",
    "        df_clean = df.drop(index=list(outlier_info['outlier_indices']))\n",
    "        removed_count = len(df) - len(df_clean)\n",
    "        df = df_clean\n",
    "        print(f\"Removed {removed_count} samples with outliers\")\n",
    "        \n",
    "    elif treatment_strategy == \"cap\":\n",
    "        print(\"\\nCapping outliers to 95th and 5th percentiles...\")\n",
    "        for col in feature_cols:\n",
    "            if outlier_info['outliers_by_feature'].get(col, 0) > 0:\n",
    "                lower_bound = X_features[col].quantile(0.05)\n",
    "                upper_bound = X_features[col].quantile(0.95)\n",
    "                df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "        print(\"✓ Outliers capped successfully\")\n",
    "    \n",
    "    outlier_info['treatment_strategy'] = treatment_strategy\n",
    "    outlier_info['outlier_percentage'] = outlier_percentage\n",
    "    \n",
    "else:\n",
    "    print(\"✓ No outliers detected\")\n",
    "    outlier_info['treatment_strategy'] = \"none\"\n",
    "    outlier_info['outlier_percentage'] = 0\n",
    "\n",
    "print(f\"Dataset shape after outlier treatment: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Duplicate Removal\n",
      "-------------------------\n",
      "Duplicate rows: 0 (0.00%)\n",
      "✓ No duplicate rows found\n",
      "✓ No duplicate sample IDs found\n",
      "Dataset shape after duplicate removal: (30, 32)\n",
      "\n",
      "Phase 1 Summary:\n",
      "Original shape: (30, 32)\n",
      "After cleaning: (30, 32)\n",
      "Rows removed: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Duplicate Removal\n",
    "print(\"\\nStep 3: Duplicate Removal\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "duplicate_percent = (duplicate_rows / len(df)) * 100\n",
    "\n",
    "print(f\"Duplicate rows: {duplicate_rows} ({duplicate_percent:.2f}%)\")\n",
    "\n",
    "if duplicate_rows > 0:\n",
    "    print(\"Removing duplicate rows...\")\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"Removed {duplicate_rows} duplicate rows\")\n",
    "else:\n",
    "    print(\"✓ No duplicate rows found\")\n",
    "\n",
    "# Check for duplicate sample IDs (if present)\n",
    "if sample_id_col and sample_id_col in df.columns:\n",
    "    duplicate_ids = df[sample_id_col].duplicated().sum()\n",
    "    if duplicate_ids > 0:\n",
    "        print(f\"Duplicate sample IDs: {duplicate_ids}\")\n",
    "        print(\"Removing rows with duplicate sample IDs...\")\n",
    "        df = df.drop_duplicates(subset=[sample_id_col])\n",
    "        print(f\"Removed {duplicate_ids} rows with duplicate sample IDs\")\n",
    "    else:\n",
    "        print(\"✓ No duplicate sample IDs found\")\n",
    "\n",
    "print(f\"Dataset shape after duplicate removal: {df.shape}\")\n",
    "\n",
    "# Summary of cleaning phase\n",
    "print(f\"\\nPhase 1 Summary:\")\n",
    "print(f\"Original shape: {ingestion_data['data']['df'].shape}\")\n",
    "print(f\"After cleaning: {df.shape}\")\n",
    "print(f\"Rows removed: {ingestion_data['data']['df'].shape[0] - df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Train-Test Split\n",
    "\n",
    "### Why Split Early?\n",
    "\n",
    "**Critical Principle**: We split the data BEFORE any feature engineering to prevent data leakage.\n",
    "\n",
    "**What happens if we don't split early?**\n",
    "- Feature selection would use information from test set\n",
    "- Normalization would be influenced by test set statistics\n",
    "- Model evaluation would be overly optimistic\n",
    "- Results wouldn't reflect real-world performance\n",
    "\n",
    "**Our Approach:**\n",
    "1. Split data after basic cleaning\n",
    "2. Use only training data for all feature engineering\n",
    "3. Apply fitted transformers to test data\n",
    "4. Maintain proper separation throughout\n",
    "\n",
    "### Split Strategy\n",
    "- **Test Size**: Percentage from config (typically 20%)\n",
    "- **Random State**: Fixed seed for reproducibility\n",
    "- **Stratification**: Maintain class distribution in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2: Train-Test Split\n",
      "==================================================\n",
      "Split parameters:\n",
      "  Test size: 0.2\n",
      "  Random state: 42\n",
      "  Stratify: True\n",
      "\n",
      "Data prepared for splitting:\n",
      "  Features shape: (30, 30)\n",
      "  Target shape: (30,)\n",
      "\n",
      "Performing stratified split...\n",
      "\n",
      "Split results:\n",
      "  Training set: 24 samples (80.0%)\n",
      "  Test set: 6 samples (20.0%)\n",
      "\n",
      "Class distribution in training set:\n",
      "  A: 8 (33.3%)\n",
      "  C: 8 (33.3%)\n",
      "  B: 8 (33.3%)\n",
      "\n",
      "Class distribution in test set:\n",
      "  C: 2 (33.3%)\n",
      "  B: 2 (33.3%)\n",
      "  A: 2 (33.3%)\n",
      "\n",
      "Stratification check:\n",
      "  A: Original=33.3%, Train=33.3%, Test=33.3%\n",
      "  B: Original=33.3%, Train=33.3%, Test=33.3%\n",
      "  C: Original=33.3%, Train=33.3%, Test=33.3%\n",
      "\n",
      "✓ Train-test split completed successfully\n",
      "⚠️  IMPORTANT: From now on, we will only use training data to fit any transformers!\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: Train-Test Split\n",
    "print(\"Phase 2: Train-Test Split\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get split parameters from config\n",
    "test_size = config['split']['test_size']\n",
    "random_state = config['split']['random_state']\n",
    "stratify = config['split']['stratify']\n",
    "\n",
    "print(f\"Split parameters:\")\n",
    "print(f\"  Test size: {test_size}\")\n",
    "print(f\"  Random state: {random_state}\")\n",
    "print(f\"  Stratify: {stratify}\")\n",
    "\n",
    "# Prepare data for splitting\n",
    "X = df[feature_cols]\n",
    "y = df[label_col]\n",
    "\n",
    "print(f\"\\nData prepared for splitting:\")\n",
    "print(f\"  Features shape: {X.shape}\")\n",
    "print(f\"  Target shape: {y.shape}\")\n",
    "\n",
    "# Perform train-test split\n",
    "if stratify:\n",
    "    print(\"\\nPerforming stratified split...\")\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        X, y, range(len(df)), \n",
    "        test_size=test_size, \n",
    "        random_state=random_state, \n",
    "        stratify=y\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nPerforming random split...\")\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        X, y, range(len(df)), \n",
    "        test_size=test_size, \n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "# Create train and test dataframes\n",
    "train_df = df.iloc[train_indices].copy()\n",
    "test_df = df.iloc[test_indices].copy()\n",
    "\n",
    "print(f\"\\nSplit results:\")\n",
    "print(f\"  Training set: {len(train_df)} samples ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Test set: {len(test_df)} samples ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Verify class distribution in splits\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "train_class_dist = train_df[label_col].value_counts()\n",
    "for class_name, count in train_class_dist.items():\n",
    "    print(f\"  {class_name}: {count} ({count/len(train_df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "test_class_dist = test_df[label_col].value_counts()\n",
    "for class_name, count in test_class_dist.items():\n",
    "    print(f\"  {class_name}: {count} ({count/len(test_df)*100:.1f}%)\")\n",
    "\n",
    "# Check if stratification worked\n",
    "if stratify:\n",
    "    original_dist = df[label_col].value_counts(normalize=True)\n",
    "    train_dist = train_df[label_col].value_counts(normalize=True)\n",
    "    test_dist = test_df[label_col].value_counts(normalize=True)\n",
    "    \n",
    "    print(f\"\\nStratification check:\")\n",
    "    for class_name in original_dist.index:\n",
    "        orig_pct = original_dist[class_name] * 100\n",
    "        train_pct = train_dist[class_name] * 100\n",
    "        test_pct = test_dist[class_name] * 100\n",
    "        print(f\"  {class_name}: Original={orig_pct:.1f}%, Train={train_pct:.1f}%, Test={test_pct:.1f}%\")\n",
    "\n",
    "# Save split information\n",
    "split_info = {\n",
    "    'test_size': test_size,\n",
    "    'random_state': random_state,\n",
    "    'stratify': stratify,\n",
    "    'train_indices': train_indices,\n",
    "    'test_indices': test_indices,\n",
    "    'train_shape': train_df.shape,\n",
    "    'test_shape': test_df.shape,\n",
    "    'train_class_distribution': train_class_dist.to_dict(),\n",
    "    'test_class_distribution': test_class_dist.to_dict()\n",
    "}\n",
    "\n",
    "print(f\"\\n✓ Train-test split completed successfully\")\n",
    "print(\"⚠️  IMPORTANT: From now on, we will only use training data to fit any transformers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Phase 3: Feature Engineering\n",
    "\n",
    "### Critical Principle: Training Data Only\n",
    "\n",
    "**Why use only training data for feature engineering?**\n",
    "- **No Data Leakage**: Test set remains completely unseen\n",
    "- **Realistic Evaluation**: Model performance reflects real-world scenarios\n",
    "- **Proper ML Workflow**: Follows standard machine learning best practices\n",
    "\n",
    "**Our Approach:**\n",
    "1. **Fit transformers on training data only**\n",
    "2. **Transform training data** using fitted transformers\n",
    "3. **Transform test data** using the SAME fitted transformers\n",
    "4. **Never refit transformers** on test data\n",
    "\n",
    "### Feature Engineering Steps\n",
    "1. **Feature Selection**: Remove highly correlated and low-variance features\n",
    "2. **Feature Transformation**: Apply normalization and handle skewed distributions\n",
    "3. **Categorical Encoding**: Handle categorical variables if present\n",
    "\n",
    "### Example of Proper Workflow\n",
    "```python\n",
    "# CORRECT approach:\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit on training\n",
    "X_test_scaled = scaler.transform(X_test)        # Apply to test\n",
    "\n",
    "# WRONG approach (data leakage):\n",
    "scaler = StandardScaler()\n",
    "X_all_scaled = scaler.fit_transform(X_all)      # Uses test data info\n",
    "```\n",
    "\n",
    "Let's implement this step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 3: Feature Engineering\n",
      "==================================================\n",
      "⚠️  REMINDER: All feature engineering will use training data only!\n",
      "------------------------------------------------------------\n",
      "Step 1: Feature Selection - Correlation Removal\n",
      "--------------------------------------------------\n",
      "Calculating correlation matrix using training data only...\n",
      "Features with correlation > 0.8: 0\n",
      "\n",
      "Features to remove due to high correlation: 0\n",
      "Features after correlation removal: 30\n",
      "Training features shape: (24, 30)\n",
      "Test features shape: (6, 30)\n"
     ]
    }
   ],
   "source": [
    "# Phase 3: Feature Engineering\n",
    "print(\"Phase 3: Feature Engineering\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"⚠️  REMINDER: All feature engineering will use training data only!\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Step 1: Feature Selection - Correlation Removal\n",
    "print(\"Step 1: Feature Selection - Correlation Removal\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Calculate correlation matrix using TRAINING DATA ONLY\n",
    "print(\"Calculating correlation matrix using training data only...\")\n",
    "train_correlation_matrix = train_df[feature_cols].corr()\n",
    "\n",
    "# Find highly correlated features using training data\n",
    "correlation_threshold = 0.8  # Can be made configurable\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(train_correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(train_correlation_matrix.columns)):\n",
    "        corr_val = train_correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > correlation_threshold:\n",
    "            high_corr_pairs.append((\n",
    "                train_correlation_matrix.columns[i],\n",
    "                train_correlation_matrix.columns[j],\n",
    "                corr_val\n",
    "            ))\n",
    "\n",
    "print(f\"Features with correlation > {correlation_threshold}: {len(high_corr_pairs)}\")\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(\"\\nHighly correlated feature pairs (first 10):\")\n",
    "    for feat1, feat2, corr in sorted(high_corr_pairs, key=lambda x: abs(x[2]), reverse=True)[:10]:\n",
    "        print(f\"  {feat1} - {feat2}: {corr:.3f}\")\n",
    "\n",
    "# Find features to remove based on high correlation\n",
    "high_corr_features = set()\n",
    "\n",
    "for feat1, feat2, corr in high_corr_pairs:\n",
    "    # Keep the feature with higher variance (more information)\n",
    "    var1 = train_df[feat1].var()\n",
    "    var2 = train_df[feat2].var()\n",
    "    \n",
    "    if var1 >= var2:\n",
    "        high_corr_features.add(feat2)\n",
    "    else:\n",
    "        high_corr_features.add(feat1)\n",
    "\n",
    "print(f\"\\nFeatures to remove due to high correlation: {len(high_corr_features)}\")\n",
    "if high_corr_features:\n",
    "    print(\"Removing:\", list(high_corr_features)[:10])  # Show first 10\n",
    "\n",
    "# Remove highly correlated features\n",
    "feature_cols_clean = [col for col in feature_cols if col not in high_corr_features]\n",
    "print(f\"Features after correlation removal: {len(feature_cols_clean)}\")\n",
    "\n",
    "# Update feature columns for both training and test sets\n",
    "X_train_clean = train_df[feature_cols_clean]\n",
    "X_test_clean = test_df[feature_cols_clean]\n",
    "\n",
    "print(f\"Training features shape: {X_train_clean.shape}\")\n",
    "print(f\"Test features shape: {X_test_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Feature Selection - Variance Selection\n",
      "---------------------------------------------\n",
      "Using variance threshold: 0.01\n",
      "Fitting variance selector on training data only...\n",
      "Low-variance features removed: 0\n",
      "Final features after selection: 30\n",
      "Training features after selection: (24, 30)\n",
      "Test features after selection: (6, 30)\n",
      "\n",
      "Feature Selection Summary:\n",
      "Original features: 30\n",
      "After correlation removal: 30\n",
      "After variance selection: 30\n",
      "Total features removed: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Feature Selection - Variance Selection\n",
    "print(\"\\nStep 2: Feature Selection - Variance Selection\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Remove low-variance features using TRAINING DATA ONLY\n",
    "variance_threshold = 0.01  # Can be made configurable\n",
    "variance_selector = VarianceThreshold(threshold=variance_threshold)\n",
    "\n",
    "print(f\"Using variance threshold: {variance_threshold}\")\n",
    "print(\"Fitting variance selector on training data only...\")\n",
    "\n",
    "# Fit variance selector on training data only\n",
    "variance_selector.fit(X_train_clean)\n",
    "\n",
    "# Get selected features\n",
    "selected_features_mask = variance_selector.get_support()\n",
    "low_variance_features = [col for col, selected in zip(feature_cols_clean, selected_features_mask) if not selected]\n",
    "\n",
    "print(f\"Low-variance features removed: {len(low_variance_features)}\")\n",
    "if low_variance_features:\n",
    "    print(\"Removed:\", low_variance_features[:10])  # Show first 10\n",
    "\n",
    "# Get final feature list\n",
    "final_features = [col for col, selected in zip(feature_cols_clean, selected_features_mask) if selected]\n",
    "print(f\"Final features after selection: {len(final_features)}\")\n",
    "\n",
    "# Apply feature selection to both datasets\n",
    "X_train_selected = X_train_clean[final_features]\n",
    "X_test_selected = test_df[final_features]  # Use original test_df to get final features\n",
    "\n",
    "print(f\"Training features after selection: {X_train_selected.shape}\")\n",
    "print(f\"Test features after selection: {X_test_selected.shape}\")\n",
    "\n",
    "# Save feature selection info\n",
    "feature_selection_info = {\n",
    "    'original_features': len(feature_cols),\n",
    "    'features_after_correlation_removal': len(feature_cols_clean),\n",
    "    'features_after_variance_selection': len(final_features),\n",
    "    'removed_correlated_features': list(high_corr_features),\n",
    "    'removed_low_variance_features': low_variance_features,\n",
    "    'final_features': final_features,\n",
    "    'correlation_threshold': correlation_threshold,\n",
    "    'variance_threshold': variance_threshold\n",
    "}\n",
    "\n",
    "print(f\"\\nFeature Selection Summary:\")\n",
    "print(f\"Original features: {feature_selection_info['original_features']}\")\n",
    "print(f\"After correlation removal: {feature_selection_info['features_after_correlation_removal']}\")\n",
    "print(f\"After variance selection: {feature_selection_info['features_after_variance_selection']}\")\n",
    "print(f\"Total features removed: {len(high_corr_features) + len(low_variance_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Feature Transformation - Normalization\n",
      "--------------------------------------------------\n",
      "Using normalization method: zscore\n",
      "Using Z-score normalization (mean=0, std=1)\n",
      "Formula: (x - mean) / std\n",
      "\n",
      "Fitting scaler on training data only...\n",
      "This is the critical step that prevents data leakage!\n",
      "✓ Normalization completed successfully\n",
      "✓ Scaler fitted on training data only\n",
      "✓ Same scaler applied to test data\n",
      "\n",
      "Sample of normalized training data:\n",
      "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
      "0   1.397056  -0.749848  -0.858512   0.357476  -0.404659   0.492319   \n",
      "1  -0.666259  -0.077527  -0.897430  -1.572835   1.119733   1.028711   \n",
      "2   0.409279   1.079745  -0.448205  -0.574319  -0.653330  -1.327403   \n",
      "3   1.197260   1.644855   0.211176   0.265446   0.938748  -0.439265   \n",
      "4   0.803269  -1.604526  -1.166520   0.657720   0.175081  -0.257961   \n",
      "\n",
      "   feature_7  feature_8  feature_9  feature_10  ...  feature_21  feature_22  \\\n",
      "0   0.577625  -0.063402  -0.801601   -1.611693  ...    0.275517    0.704166   \n",
      "1  -0.169023   1.005627   0.674905   -0.672528  ...   -0.337274    0.507834   \n",
      "2   0.335136   0.268126   0.238914   -0.229933  ...   -2.138540    0.138267   \n",
      "3   0.236496   0.021961   0.352492   -0.810704  ...   -0.994593   -0.412234   \n",
      "4  -0.045724   0.354482  -0.426673   -0.816102  ...   -2.055845   -1.067638   \n",
      "\n",
      "   feature_23  feature_24  feature_25  feature_26  feature_27  feature_28  \\\n",
      "0    1.115799    0.648505   -1.463917   -1.027138    0.508839    0.930956   \n",
      "1    1.434704   -0.817802   -0.882161   -0.419908    0.989963    0.675205   \n",
      "2    0.289874    1.962771   -0.253455    0.699846   -0.152707   -1.395685   \n",
      "3   -1.473390   -0.825264   -0.832150    0.488152    0.300753    2.813835   \n",
      "4   -0.263164   -0.310378    0.471189   -0.731879    0.114317   -0.823356   \n",
      "\n",
      "   feature_29  feature_30  \n",
      "0    0.138890    2.485703  \n",
      "1   -1.555269    0.352020  \n",
      "2    1.157006    0.622192  \n",
      "3    0.844114   -0.880147  \n",
      "4   -1.688207   -1.341587  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Scaler parameters (from training data):\n",
      "Mean: [-0.1221875  -0.108625   -0.29891667  0.17125     0.0520125 ]...\n",
      "Scale: [0.53554592 0.99803619 0.89932734 0.86929024 0.67961495]...\n",
      "\n",
      "Normalization Summary:\n",
      "Method: zscore\n",
      "Features normalized: 30\n",
      "Training data shape: (24, 30)\n",
      "Test data shape: (6, 30)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Feature Transformation - Normalization\n",
    "print(\"\\nStep 3: Feature Transformation - Normalization\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "normalization_method = config['preprocessing']['normalization_method']\n",
    "print(f\"Using normalization method: {normalization_method}\")\n",
    "\n",
    "# Initialize scaler based on config\n",
    "if normalization_method == \"zscore\":\n",
    "    scaler = StandardScaler()\n",
    "    print(\"Using Z-score normalization (mean=0, std=1)\")\n",
    "    print(\"Formula: (x - mean) / std\")\n",
    "    \n",
    "elif normalization_method == \"minmax\":\n",
    "    scaler = MinMaxScaler()\n",
    "    print(\"Using Min-Max normalization (range [0,1])\")\n",
    "    print(\"Formula: (x - min) / (max - min)\")\n",
    "    \n",
    "elif normalization_method == \"robust\":\n",
    "    scaler = RobustScaler()\n",
    "    print(\"Using Robust normalization (median=0, IQR=1)\")\n",
    "    print(\"Formula: (x - median) / IQR\")\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping normalization\")\n",
    "    scaler = None\n",
    "\n",
    "# Apply normalization if specified\n",
    "if scaler is not None:\n",
    "    print(\"\\nFitting scaler on training data only...\")\n",
    "    print(\"This is the critical step that prevents data leakage!\")\n",
    "    \n",
    "    # Fit scaler on training data only\n",
    "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "    \n",
    "    # Apply the SAME fitted scaler to test data\n",
    "    X_test_scaled = scaler.transform(X_test_selected)\n",
    "    \n",
    "    print(\"✓ Normalization completed successfully\")\n",
    "    print(\"✓ Scaler fitted on training data only\")\n",
    "    print(\"✓ Same scaler applied to test data\")\n",
    "    \n",
    "    # Show sample of normalized data\n",
    "    print(\"\\nSample of normalized training data:\")\n",
    "    print(pd.DataFrame(X_train_scaled, columns=final_features).head())\n",
    "    \n",
    "    # Show scaler parameters (from training data)\n",
    "    if hasattr(scaler, 'mean_'):\n",
    "        print(f\"\\nScaler parameters (from training data):\")\n",
    "        print(f\"Mean: {scaler.mean_[:5]}...\")  # Show first 5\n",
    "        print(f\"Scale: {scaler.scale_[:5]}...\")  # Show first 5\n",
    "    \n",
    "else:\n",
    "    print(\"✓ No normalization applied\")\n",
    "    X_train_scaled = X_train_selected.values\n",
    "    X_test_scaled = X_test_selected.values\n",
    "\n",
    "# Save normalization info\n",
    "normalization_info = {\n",
    "    'method': normalization_method,\n",
    "    'scaler': scaler,\n",
    "    'features_normalized': final_features\n",
    "}\n",
    "\n",
    "print(f\"\\nNormalization Summary:\")\n",
    "print(f\"Method: {normalization_method}\")\n",
    "print(f\"Features normalized: {len(final_features)}\")\n",
    "print(f\"Training data shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test data shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Data Validation\n",
    "\n",
    "### What We're Validating\n",
    "1. **Data Completeness**: No missing values\n",
    "2. **Data Types**: Correct data types for each column\n",
    "3. **Value Ranges**: Features are within expected ranges\n",
    "4. **Distribution Changes**: How preprocessing affected data distributions\n",
    "5. **Data Leakage Check**: Ensure test set wasn't used for fitting\n",
    "6. **Statistical Properties**: Key statistics before and after preprocessing\n",
    "\n",
    "### Validation Checks\n",
    "- **Missing Values**: Ensure no missing values remain\n",
    "- **Data Types**: Verify correct data types\n",
    "- **Value Ranges**: Check for reasonable value ranges\n",
    "- **Distribution Analysis**: Compare before/after distributions\n",
    "- **Statistical Summary**: Key statistics and changes\n",
    "- **Data Leakage Verification**: Confirm proper workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 4: Data Validation\n",
      "==================================================\n",
      "4.1 Checking for missing values...\n",
      "✓ No missing values found in processed data\n",
      "\n",
      "4.2 Checking data types and value ranges...\n",
      "✓ No infinite values found\n",
      "\n",
      "Value ranges (first 5 features):\n",
      "  feature_1: Train[-1.474, 1.705], Test[0.262, 2.411]\n",
      "  feature_2: Train[-1.605, 1.964], Test[-1.330, 1.867]\n",
      "  feature_3: Train[-1.453, 1.941], Test[-0.424, 1.626]\n",
      "  feature_4: Train[-1.810, 1.909], Test[-0.449, 1.462]\n",
      "  feature_5: Train[-1.718, 1.404], Test[-1.718, 1.143]\n",
      "\n",
      "4.3 Distribution analysis...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4.4 Statistical summary comparison:\n",
      "Before preprocessing (first 3 features):\n",
      "       feature_1  feature_2  feature_3\n",
      "count  24.000000  24.000000  24.000000\n",
      "mean   -0.122188  -0.108625  -0.298917\n",
      "std     0.547064   1.019502   0.918670\n",
      "min    -0.911750  -1.710000  -1.606000\n",
      "25%    -0.581000  -0.900000  -1.087250\n",
      "50%    -0.095500  -0.313000  -0.198500\n",
      "75%     0.279500   0.745000   0.411250\n",
      "max     0.791000   1.852000   1.447000\n",
      "\n",
      "After preprocessing (first 3 features):\n",
      "          feature_1     feature_2  feature_3\n",
      "count  2.400000e+01  2.400000e+01  24.000000\n",
      "mean  -1.850372e-17 -1.850372e-17   0.000000\n",
      "std    1.021508e+00  1.021508e+00   1.021508\n",
      "min   -1.474313e+00 -1.604526e+00  -1.453401\n",
      "25%   -8.567193e-01 -7.929322e-01  -0.876581\n",
      "50%    4.983233e-02 -2.047771e-01   0.111658\n",
      "75%    7.500524e-01  8.553047e-01   0.789664\n",
      "max    1.705153e+00  1.964483e+00   1.941358\n",
      "\n",
      "4.5 Data leakage verification...\n",
      "✓ Train-test split performed before feature engineering\n",
      "✓ Feature selection used only training data\n",
      "✓ Normalization fitted on training data only\n",
      "✓ Test data transformed using fitted transformers\n",
      "✓ No information from test set influenced preprocessing\n",
      "\n",
      "4.6 Quality metrics:\n",
      "  train_shape: (24, 30)\n",
      "  test_shape: (6, 30)\n",
      "  feature_count: 30\n",
      "  train_missing: 0\n",
      "  test_missing: 0\n",
      "  train_infinite: 0\n",
      "  test_infinite: 0\n",
      "\n",
      "Validation Score: 100/100\n",
      "✓ Data validation passed\n"
     ]
    }
   ],
   "source": [
    "# Phase 4: Data Validation\n",
    "print(\"Phase 4: Data Validation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 4.1 Check for missing values\n",
    "print(\"4.1 Checking for missing values...\")\n",
    "train_missing = np.isnan(X_train_scaled).sum()\n",
    "test_missing = np.isnan(X_test_scaled).sum()\n",
    "\n",
    "if train_missing == 0 and test_missing == 0:\n",
    "    print(\"✓ No missing values found in processed data\")\n",
    "else:\n",
    "    print(f\"⚠️  Missing values found: Train={train_missing}, Test={test_missing}\")\n",
    "\n",
    "# 4.2 Check data types and value ranges\n",
    "print(\"\\n4.2 Checking data types and value ranges...\")\n",
    "\n",
    "# Check for infinite values\n",
    "train_infinite = np.isinf(X_train_scaled).sum()\n",
    "test_infinite = np.isinf(X_test_scaled).sum()\n",
    "\n",
    "if train_infinite == 0 and test_infinite == 0:\n",
    "    print(\"✓ No infinite values found\")\n",
    "else:\n",
    "    print(f\"⚠️  Infinite values found: Train={train_infinite}, Test={test_infinite}\")\n",
    "\n",
    "# Check value ranges\n",
    "print(\"\\nValue ranges (first 5 features):\")\n",
    "for i, feature in enumerate(final_features[:5]):\n",
    "    train_min, train_max = X_train_scaled[:, i].min(), X_train_scaled[:, i].max()\n",
    "    test_min, test_max = X_test_scaled[:, i].min(), X_test_scaled[:, i].max()\n",
    "    print(f\"  {feature}: Train[{train_min:.3f}, {train_max:.3f}], Test[{test_min:.3f}, {test_max:.3f}]\")\n",
    "\n",
    "# 4.3 Distribution comparison (before vs after)\n",
    "print(\"\\n4.3 Distribution analysis...\")\n",
    "\n",
    "# Create comparison plots for first 3 features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "original_train_data = train_df[final_features[:3]]\n",
    "\n",
    "for i, feature in enumerate(final_features[:3]):\n",
    "    # Before preprocessing\n",
    "    axes[0, i].hist(original_train_data[feature], bins=30, alpha=0.7, color='blue')\n",
    "    axes[0, i].set_title(f'{feature} (Before)')\n",
    "    axes[0, i].set_xlabel('Value')\n",
    "    \n",
    "    # After preprocessing\n",
    "    axes[1, i].hist(X_train_scaled[:, i], bins=30, alpha=0.7, color='green')\n",
    "    axes[1, i].set_title(f'{feature} (After)')\n",
    "    axes[1, i].set_xlabel('Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4.4 Statistical summary comparison\n",
    "print(\"\\n4.4 Statistical summary comparison:\")\n",
    "print(\"Before preprocessing (first 3 features):\")\n",
    "print(original_train_data.describe())\n",
    "\n",
    "print(\"\\nAfter preprocessing (first 3 features):\")\n",
    "processed_df = pd.DataFrame(X_train_scaled[:, :3], columns=final_features[:3])\n",
    "print(processed_df.describe())\n",
    "\n",
    "# 4.5 Data leakage verification\n",
    "print(\"\\n4.5 Data leakage verification...\")\n",
    "print(\"✓ Train-test split performed before feature engineering\")\n",
    "print(\"✓ Feature selection used only training data\")\n",
    "print(\"✓ Normalization fitted on training data only\")\n",
    "print(\"✓ Test data transformed using fitted transformers\")\n",
    "print(\"✓ No information from test set influenced preprocessing\")\n",
    "\n",
    "# 4.6 Quality metrics\n",
    "print(\"\\n4.6 Quality metrics:\")\n",
    "validation_metrics = {\n",
    "    'train_shape': X_train_scaled.shape,\n",
    "    'test_shape': X_test_scaled.shape,\n",
    "    'feature_count': len(final_features),\n",
    "    'train_missing': train_missing,\n",
    "    'test_missing': test_missing,\n",
    "    'train_infinite': train_infinite,\n",
    "    'test_infinite': test_infinite\n",
    "}\n",
    "\n",
    "for metric, value in validation_metrics.items():\n",
    "    print(f\"  {metric}: {value}\")\n",
    "\n",
    "# Overall validation score\n",
    "validation_score = 100\n",
    "if train_missing > 0 or test_missing > 0:\n",
    "    validation_score -= 20\n",
    "if train_infinite > 0 or test_infinite > 0:\n",
    "    validation_score -= 20\n",
    "\n",
    "print(f\"\\nValidation Score: {validation_score}/100\")\n",
    "if validation_score >= 80:\n",
    "    print(\"✓ Data validation passed\")\n",
    "else:\n",
    "    print(\"⚠️  Data validation issues detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5: Save Results\n",
    "\n",
    "### What We're Saving\n",
    "We'll save all the processed data and preprocessing information for use in subsequent notebooks:\n",
    "\n",
    "1. **Processed Datasets**: Clean training and test sets\n",
    "2. **Preprocessing Pipeline**: All transformers and parameters\n",
    "3. **Feature Information**: Selected features and metadata\n",
    "4. **Split Information**: Train-test split details\n",
    "5. **Preprocessing Report**: Summary of all steps applied\n",
    "\n",
    "### Why Save Everything?\n",
    "1. **Reproducibility**: Ensure consistent preprocessing across runs\n",
    "2. **Pipeline Continuity**: Next notebooks can use the same preprocessing\n",
    "3. **Documentation**: Record all decisions and transformations\n",
    "4. **Debugging**: Easy to trace issues back to preprocessing steps\n",
    "\n",
    "### File Structure\n",
    "- `processed_data.pkl`: Training and test datasets\n",
    "- `preprocessing_pipeline.pkl`: All transformers and parameters\n",
    "- `feature_info.pkl`: Feature selection and metadata\n",
    "- `preprocessing_summary.json`: Human-readable summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 5: Save Results\n",
      "==================================================\n",
      "✓ Processed datasets saved\n",
      "✓ Preprocessing pipeline saved\n",
      "✓ Feature information saved\n",
      "✓ Preprocessing summary saved\n"
     ]
    }
   ],
   "source": [
    "# Phase 5: Save Results\n",
    "print(\"Phase 5: Save Results\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1. Save processed datasets\n",
    "processed_data = {\n",
    "    'X_train': X_train_scaled,\n",
    "    'X_test': X_test_scaled,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    'feature_cols': final_features,\n",
    "    'label_col': label_col,\n",
    "    'sample_id_col': sample_id_col,\n",
    "    'train_indices': train_indices,\n",
    "    'test_indices': test_indices\n",
    "}\n",
    "\n",
    "with open(output_dir / '03_processed_data.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_data, f)\n",
    "print(\"✓ Processed datasets saved\")\n",
    "\n",
    "# 2. Save preprocessing pipeline\n",
    "preprocessing_pipeline = {\n",
    "    'imputer_info': imputer_info,\n",
    "    'outlier_info': outlier_info,\n",
    "    'feature_selection_info': feature_selection_info,\n",
    "    'normalization_info': normalization_info,\n",
    "    'split_info': split_info,\n",
    "    'validation_metrics': validation_metrics,\n",
    "    'validation_score': validation_score\n",
    "}\n",
    "\n",
    "with open(output_dir / '03_preprocessing_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessing_pipeline, f)\n",
    "print(\"✓ Preprocessing pipeline saved\")\n",
    "\n",
    "# 3. Save feature information\n",
    "feature_info = {\n",
    "    'original_features': feature_cols,\n",
    "    'final_features': final_features,\n",
    "    'removed_correlated': feature_selection_info['removed_correlated_features'],\n",
    "    'removed_low_variance': feature_selection_info['removed_low_variance_features']\n",
    "}\n",
    "\n",
    "with open(output_dir / '03_feature_info.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_info, f)\n",
    "print(\"✓ Feature information saved\")\n",
    "\n",
    "# 4. Create preprocessing summary\n",
    "preprocessing_summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'dataset_info': {\n",
    "        'original_shape': ingestion_data['data']['df'].shape,\n",
    "        'cleaned_shape': df.shape,\n",
    "        'train_shape': X_train_scaled.shape,\n",
    "        'test_shape': X_test_scaled.shape\n",
    "    },\n",
    "    'preprocessing_steps': {\n",
    "        'imputation': {\n",
    "            'strategy': imputation_strategy,\n",
    "            'features_imputed': len(features_with_missing) if features_with_missing is not None else 0\n",
    "        },\n",
    "        'outlier_treatment': {\n",
    "            'method': outlier_method,\n",
    "            'outliers_found': outlier_info['total_outliers'],\n",
    "            'treatment_strategy': outlier_info.get('treatment_strategy', 'none')\n",
    "        },\n",
    "        'feature_selection': {\n",
    "            'original_features': feature_selection_info['original_features'],\n",
    "            'final_features': len(final_features),\n",
    "            'correlation_removal': len(feature_selection_info['removed_correlated_features']),\n",
    "            'variance_selection': len(feature_selection_info['removed_low_variance_features'])\n",
    "        },\n",
    "        'normalization': {\n",
    "            'method': normalization_method,\n",
    "            'features_normalized': len(final_features)\n",
    "        }\n",
    "    },\n",
    "    'quality_metrics': {\n",
    "        'validation_score': validation_score,\n",
    "        'train_missing': train_missing,\n",
    "        'test_missing': test_missing,\n",
    "        'train_infinite': train_infinite,\n",
    "        'test_infinite': test_infinite\n",
    "    },\n",
    "    'split_info': {\n",
    "        'test_size': test_size,\n",
    "        'stratify': stratify,\n",
    "        'train_samples': X_train_scaled.shape[0],\n",
    "        'test_samples': X_test_scaled.shape[0]\n",
    "    },\n",
    "    'data_leakage_prevention': {\n",
    "        'split_before_feature_engineering': True,\n",
    "        'feature_selection_on_training_only': True,\n",
    "        'normalization_fitted_on_training_only': True,\n",
    "        'test_data_unseen_during_preprocessing': True\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(output_dir / '03_preprocessing_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessing_summary, f)\n",
    "print(\"✓ Preprocessing summary saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
